{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alma.mbaPreprocessing",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYhOC3zYPBLWvmx/gVDmmb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tg2718/Projects-Python-work/blob/main/Alma_mbaPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPXlgnGLpOXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "faf3f335-80e6-4073-8644-2e9321277d84"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install openpyxl\n",
        "!pip install fuzzywuzzy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "from fuzzywuzzy import process, fuzz\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#import modules\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.special as spsp\n",
        "import scipy.stats as spst\n",
        "from statsmodels.base.model import GenericLikelihoodModel\n",
        "import datetime as dt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (2.5.9)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl) (1.0.1)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl) (1.4.1)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Oq-KBTpWiD",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "4f9940b6-af51-4b01-d570-25421b68c3c9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "\n",
        "data1 = io.BytesIO(uploaded['Model - Data - Relevant Data for model.csv'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ba92c93-b6f8-43fb-8213-b17c5eac56d2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ba92c93-b6f8-43fb-8213-b17c5eac56d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Model - Data - Relevant Data for model.csv to Model - Data - Relevant Data for model.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6KjSaGBphqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "outputId": "5e5597c2-53b4-4318-da7c-e929e2dc2de1"
      },
      "source": [
        "df = pd.read_csv(data1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Full name</th>\n",
              "      <th>Tier1Exp</th>\n",
              "      <th>Tier2Exp</th>\n",
              "      <th>Tier3Exp</th>\n",
              "      <th>Tier4Exp</th>\n",
              "      <th>Tier5Exp</th>\n",
              "      <th>TotalWorkExp</th>\n",
              "      <th>Swtich</th>\n",
              "      <th>MasDate</th>\n",
              "      <th>Type1</th>\n",
              "      <th>Bachelors1</th>\n",
              "      <th>Master1</th>\n",
              "      <th>MBA1</th>\n",
              "      <th>EdTier1</th>\n",
              "      <th>Type2</th>\n",
              "      <th>Bachelors2</th>\n",
              "      <th>Master2</th>\n",
              "      <th>MBA2</th>\n",
              "      <th>EdTier2</th>\n",
              "      <th>Type3</th>\n",
              "      <th>Bachelors3</th>\n",
              "      <th>Master3</th>\n",
              "      <th>MBA3</th>\n",
              "      <th>EdTier3</th>\n",
              "      <th>Type4</th>\n",
              "      <th>Bachelors4</th>\n",
              "      <th>Master4</th>\n",
              "      <th>MBA4</th>\n",
              "      <th>EdTier4</th>\n",
              "      <th>Type5</th>\n",
              "      <th>Bachelors5</th>\n",
              "      <th>Master5</th>\n",
              "      <th>MBA5</th>\n",
              "      <th>EdTier5</th>\n",
              "      <th>Type6</th>\n",
              "      <th>Bachelors6</th>\n",
              "      <th>Master6</th>\n",
              "      <th>MBA6</th>\n",
              "      <th>EdTier6</th>\n",
              "      <th>BachTier</th>\n",
              "      <th>MBA_tier</th>\n",
              "      <th>MBA_req_1</th>\n",
              "      <th>ActualMBA</th>\n",
              "      <th>School</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kritika Taneja</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4107</td>\n",
              "      <td>4</td>\n",
              "      <td>2019</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Priya Gaur</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2804</td>\n",
              "      <td>2</td>\n",
              "      <td>2019</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>University</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amrinder Singh Chawla</td>\n",
              "      <td>0</td>\n",
              "      <td>1096</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1918</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prateet Garg</td>\n",
              "      <td>731</td>\n",
              "      <td>730</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1461</td>\n",
              "      <td>2</td>\n",
              "      <td>2018</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Commerce</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Commerce</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shreyas Lakshminarayan</td>\n",
              "      <td>0</td>\n",
              "      <td>1308</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2495</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>Shariq Mirza, CFA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1065</td>\n",
              "      <td>0</td>\n",
              "      <td>2013</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>Niyanta Mogre</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2375</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065</th>\n",
              "      <td>Rutika Dhuru</td>\n",
              "      <td>1643</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1765</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>Roohi Advani</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2952</td>\n",
              "      <td>2</td>\n",
              "      <td>2014</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>University</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>Prachi Patke</td>\n",
              "      <td>0</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1403</td>\n",
              "      <td>4</td>\n",
              "      <td>2020</td>\n",
              "      <td>Management</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1068 rows Ã— 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Full name  Tier1Exp  ...  ActualMBA                        School\n",
              "0             Kritika Taneja         0  ...          1      Columbia Business School\n",
              "1                 Priya Gaur         0  ...          1      Columbia Business School\n",
              "2      Amrinder Singh Chawla         0  ...          1      Columbia Business School\n",
              "3               Prateet Garg       731  ...          1      Columbia Business School\n",
              "4     Shreyas Lakshminarayan         0  ...          1      Columbia Business School\n",
              "...                      ...       ...  ...        ...                           ...\n",
              "1063       Shariq Mirza, CFA         0  ...          1  NYU Stern School of Business\n",
              "1064           Niyanta Mogre         0  ...          1  NYU Stern School of Business\n",
              "1065            Rutika Dhuru      1643  ...          1  NYU Stern School of Business\n",
              "1066            Roohi Advani         0  ...          1  NYU Stern School of Business\n",
              "1067            Prachi Patke         0  ...          1  NYU Stern School of Business\n",
              "\n",
              "[1068 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FTXCgdhXQnv"
      },
      "source": [
        "df[\"Bachelors1\"] = df[\"Bachelors1\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Bachelors2\"] = df[\"Bachelors2\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Bachelors3\"] = df[\"Bachelors3\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Bachelors4\"] = df[\"Bachelors4\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Bachelors5\"] = df[\"Bachelors5\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Bachelors6\"] = df[\"Bachelors6\"].map({'YES': 1}).fillna(0)\n",
        "\n",
        "df[\"Master1\"] = df[\"Master1\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Master2\"] = df[\"Master2\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Master3\"] = df[\"Master3\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Master4\"] = df[\"Master4\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Master5\"] = df[\"Master5\"].map({'YES': 1}).fillna(0)\n",
        "df[\"Master6\"] = df[\"Master6\"].map({'YES': 1}).fillna(0)\n",
        "\n",
        "df[\"MBA1\"]= df[\"MBA1\"].map({'YES': 1}).fillna(0)\n",
        "df[\"MBA2\"]= df[\"MBA2\"].map({'YES': 1}).fillna(0)\n",
        "df[\"MBA3\"]= df[\"MBA3\"].map({'YES': 1}).fillna(0)\n",
        "df[\"MBA4\"]= df[\"MBA4\"].map({'YES': 1}).fillna(0)\n",
        "df[\"MBA5\"]= df[\"MBA5\"].map({'YES': 1}).fillna(0)\n",
        "df[\"MBA6\"]= df[\"MBA6\"].map({'YES': 1}).fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I10-GQ0XFM_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "889a2ee5-1144-42ec-b382-1aeb4fe40d4d"
      },
      "source": [
        "df.loc[((df[\"Master1\"]!=0) & (df[\"MBA1\"]==0)),\"RevMasterTier1\"] = df[\"EdTier1\"]\n",
        "df.loc[((df[\"Master2\"]!=0) & (df[\"MBA2\"]==0)),\"RevMasterTier2\"] = df[\"EdTier2\"]\n",
        "df.loc[((df[\"Master3\"]!=0) & (df[\"MBA3\"]==0)),\"RevMasterTier3\"] = df[\"EdTier3\"]\n",
        "df.loc[((df[\"Master4\"]!=0) & (df[\"MBA4\"]==0)),\"RevMasterTier4\"] = df[\"EdTier4\"]\n",
        "df.loc[((df[\"Master5\"]!=0) & (df[\"MBA5\"]==0)),\"RevMasterTier5\"] = df[\"EdTier5\"]\n",
        "df.loc[((df[\"Master6\"]!=0) & (df[\"MBA6\"]==0)),\"RevMasterTier6\"] = df[\"EdTier6\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df[\"RevMasterTier1\"]=df[\"RevMasterTier1\"].fillna(7)\n",
        "df[\"RevMasterTier2\"]=df[\"RevMasterTier2\"].fillna(7)\n",
        "df[\"RevMasterTier3\"]=df[\"RevMasterTier3\"].fillna(7)\n",
        "df[\"RevMasterTier4\"]=df[\"RevMasterTier4\"].fillna(7)\n",
        "df[\"RevMasterTier5\"]=df[\"RevMasterTier5\"].fillna(7)\n",
        "df[\"RevMasterTier6\"]=df[\"RevMasterTier6\"].fillna(7)\n",
        "\n",
        "df[\"RevMasterTier1\"]=df[\"RevMasterTier1\"].astype(float)\n",
        "df[\"RevMasterTier2\"]=df[\"RevMasterTier2\"].astype(float)\n",
        "df[\"RevMasterTier3\"]=df[\"RevMasterTier3\"].astype(float)\n",
        "df[\"RevMasterTier4\"]=df[\"RevMasterTier4\"].astype(float)\n",
        "df[\"RevMasterTier5\"]=df[\"RevMasterTier5\"].astype(float)\n",
        "df[\"RevMasterTier6\"]=df[\"RevMasterTier6\"].astype(float)\n",
        "\n",
        "df[\"MasterTier\"]=df[['RevMasterTier1', 'RevMasterTier2','RevMasterTier3','RevMasterTier4','RevMasterTier5',\"RevMasterTier6\"]].min(axis=1)\n",
        "\n",
        "\n",
        "df[\"MasterTier\"]=df[\"MasterTier\"].replace(7,0)\n",
        "df[\"MasterTier\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.0\n",
              "1       0.0\n",
              "2       1.0\n",
              "3       1.0\n",
              "4       1.0\n",
              "       ... \n",
              "1063    0.0\n",
              "1064    0.0\n",
              "1065    0.0\n",
              "1066    0.0\n",
              "1067    0.0\n",
              "Name: MasterTier, Length: 1068, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raj0hW4wcRzV"
      },
      "source": [
        "df.loc[((df[\"Bachelors1\"]!=0) & (df[\"MBA1\"]==0)),\"Bach_Deg\"] = df[\"Type1\"]\n",
        "df.loc[((df[\"Bachelors2\"]!=0) & (df[\"MBA2\"]==0)),\"Bach_Deg\"] = df[\"Type2\"]\n",
        "df.loc[((df[\"Bachelors3\"]!=0) & (df[\"MBA3\"]==0)),\"Bach_Deg\"] = df[\"Type3\"]\n",
        "df.loc[((df[\"Bachelors4\"]!=0) & (df[\"MBA4\"]==0)),\"Bach_Deg\"] = df[\"Type4\"]\n",
        "df.loc[((df[\"Bachelors5\"]!=0) & (df[\"MBA5\"]==0)),\"Bach_Deg\"] = df[\"Type5\"]\n",
        "df.loc[((df[\"Bachelors6\"]!=0) & (df[\"MBA6\"]==0)),\"Bach_Deg\"] = df[\"Type6\"]\n",
        "\n",
        "df.loc[((df[\"Master1\"]!=0) & (df[\"MBA1\"]==0)),\"Mast_Deg\"] = df[\"Type1\"]\n",
        "df.loc[((df[\"Master2\"]!=0) & (df[\"MBA2\"]==0)),\"Mast_Deg\"] = df[\"Type2\"]\n",
        "df.loc[((df[\"Master3\"]!=0) & (df[\"MBA3\"]==0)),\"Mast_Deg\"] = df[\"Type3\"]\n",
        "df.loc[((df[\"Master4\"]!=0) & (df[\"MBA4\"]==0)),\"Mast_Deg\"] = df[\"Type4\"]\n",
        "df.loc[((df[\"Master5\"]!=0) & (df[\"MBA5\"]==0)),\"Mast_Deg\"] = df[\"Type5\"]\n",
        "df.loc[((df[\"Master6\"]!=0) & (df[\"MBA6\"]==0)),\"Mast_Deg\"] = df[\"Type6\"]\n",
        "\n",
        "df[\"Mast_Deg\"] = df[\"Mast_Deg\"].fillna(0)\n",
        "df[\"Bach_Deg\"] = df[\"Bach_Deg\"].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diMNraVgcmeH"
      },
      "source": [
        "df\n",
        "df[\"School\"] = df[\"School\"].map(lambda x:x.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOrh6Zr5Y-XI"
      },
      "source": [
        "\n",
        "dfwd = df.drop(df[df[\"School\"]==\"The Wharton School\"].index.tolist()[110:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op2j9ZQNZ4Ft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "outputId": "cca89cf0-c655-4f5b-f119-dc4e01ce610e"
      },
      "source": [
        "dfwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Full name</th>\n",
              "      <th>Tier1Exp</th>\n",
              "      <th>Tier2Exp</th>\n",
              "      <th>Tier3Exp</th>\n",
              "      <th>Tier4Exp</th>\n",
              "      <th>Tier5Exp</th>\n",
              "      <th>TotalWorkExp</th>\n",
              "      <th>Swtich</th>\n",
              "      <th>MasDate</th>\n",
              "      <th>Type1</th>\n",
              "      <th>Bachelors1</th>\n",
              "      <th>Master1</th>\n",
              "      <th>MBA1</th>\n",
              "      <th>EdTier1</th>\n",
              "      <th>Type2</th>\n",
              "      <th>Bachelors2</th>\n",
              "      <th>Master2</th>\n",
              "      <th>MBA2</th>\n",
              "      <th>EdTier2</th>\n",
              "      <th>Type3</th>\n",
              "      <th>Bachelors3</th>\n",
              "      <th>Master3</th>\n",
              "      <th>MBA3</th>\n",
              "      <th>EdTier3</th>\n",
              "      <th>Type4</th>\n",
              "      <th>Bachelors4</th>\n",
              "      <th>Master4</th>\n",
              "      <th>MBA4</th>\n",
              "      <th>EdTier4</th>\n",
              "      <th>Type5</th>\n",
              "      <th>Bachelors5</th>\n",
              "      <th>Master5</th>\n",
              "      <th>MBA5</th>\n",
              "      <th>EdTier5</th>\n",
              "      <th>Type6</th>\n",
              "      <th>Bachelors6</th>\n",
              "      <th>Master6</th>\n",
              "      <th>MBA6</th>\n",
              "      <th>EdTier6</th>\n",
              "      <th>BachTier</th>\n",
              "      <th>MBA_tier</th>\n",
              "      <th>MBA_req_1</th>\n",
              "      <th>ActualMBA</th>\n",
              "      <th>School</th>\n",
              "      <th>RevMasterTier1</th>\n",
              "      <th>RevMasterTier2</th>\n",
              "      <th>RevMasterTier3</th>\n",
              "      <th>RevMasterTier4</th>\n",
              "      <th>RevMasterTier5</th>\n",
              "      <th>RevMasterTier6</th>\n",
              "      <th>MasterTier</th>\n",
              "      <th>Bach_Deg</th>\n",
              "      <th>Mast_Deg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kritika Taneja</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4107</td>\n",
              "      <td>4</td>\n",
              "      <td>2019</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Priya Gaur</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2804</td>\n",
              "      <td>2</td>\n",
              "      <td>2019</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>University</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>University</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amrinder Singh Chawla</td>\n",
              "      <td>0</td>\n",
              "      <td>1096</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1918</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prateet Garg</td>\n",
              "      <td>731</td>\n",
              "      <td>730</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1461</td>\n",
              "      <td>2</td>\n",
              "      <td>2018</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Commerce</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Commerce</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Commerce</td>\n",
              "      <td>Commerce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shreyas Lakshminarayan</td>\n",
              "      <td>0</td>\n",
              "      <td>1308</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2495</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>Shariq Mirza, CFA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1065</td>\n",
              "      <td>0</td>\n",
              "      <td>2013</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>Niyanta Mogre</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2375</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065</th>\n",
              "      <td>Rutika Dhuru</td>\n",
              "      <td>1643</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1765</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>Roohi Advani</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2952</td>\n",
              "      <td>2</td>\n",
              "      <td>2014</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>University</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>University</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>Prachi Patke</td>\n",
              "      <td>0</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1403</td>\n",
              "      <td>4</td>\n",
              "      <td>2020</td>\n",
              "      <td>Management</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>998 rows Ã— 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Full name  Tier1Exp  ...     Bach_Deg  Mast_Deg\n",
              "0             Kritika Taneja         0  ...            0         0\n",
              "1                 Priya Gaur         0  ...   University         0\n",
              "2      Amrinder Singh Chawla         0  ...            0         0\n",
              "3               Prateet Garg       731  ...     Commerce  Commerce\n",
              "4     Shreyas Lakshminarayan         0  ...  Engineering         0\n",
              "...                      ...       ...  ...          ...       ...\n",
              "1063       Shariq Mirza, CFA         0  ...  Engineering         0\n",
              "1064           Niyanta Mogre         0  ...  Engineering         0\n",
              "1065            Rutika Dhuru      1643  ...  Engineering         0\n",
              "1066            Roohi Advani         0  ...   University         0\n",
              "1067            Prachi Patke         0  ...  Engineering         0\n",
              "\n",
              "[998 rows x 53 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z41yEphPptmo"
      },
      "source": [
        "dfwd= pd.concat((pd.get_dummies(dfwd['Bach_Deg'], prefix = 'B'), dfwd), axis = 1).drop(['Bach_Deg'], axis = 1)\n",
        "dfwd =pd.concat((pd.get_dummies(dfwd['Mast_Deg'], prefix = 'M'), dfwd), axis = 1).drop(['Mast_Deg'], axis = 1)\n",
        "\n",
        "dfwd=dfwd.drop(columns=[\"Full name\",'Tier1Exp',\"Tier2Exp\",\"Tier3Exp\",\"Tier4Exp\",\"Tier5Exp\",\"MasDate\",\"Type1\",\t\"Bachelors1\",\t\"Master1\",\t\"MBA1\",\t\"EdTier1\",\t\"Type2\",\t\"Bachelors2\",\t\"Master2\",\t\"MBA2\",\t\"EdTier2\",\t\"Type3\",\t\"Bachelors3\",\t\"Master3\",\t\"MBA3\",\t\"EdTier3\"\t,\"Type4\"\t,\"Bachelors4\",\"Master4\",\t\"MBA4\",\t\"EdTier4\",\t\"Type5\",\t\"Bachelors5\",\t\"Master5\"\t,\"MBA5\",\"EdTier5\",\"Type6\",\t\"Bachelors6\",\t\"Master6\", \"MBA6\",\t\"EdTier6\",\"ActualMBA\",\"RevMasterTier1\",\"RevMasterTier2\",\"RevMasterTier3\",\"RevMasterTier4\",\"RevMasterTier5\",\"RevMasterTier6\",\"MBA_tier\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7RBSv-3PpE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "bdf40638-7716-4dd0-bfc3-c2f2231717f8"
      },
      "source": [
        "dfwd[\"Bucket\"].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    512\n",
              "3    330\n",
              "2    156\n",
              "Name: Bucket, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQtiNhPez6dp"
      },
      "source": [
        "dfwd[\"Bucket\"] = 0\n",
        "dfwd.loc[(df[\"School\"] == \"Columbia Business School\"),\"Bucket\"] = 1\n",
        "dfwd.loc[(df[\"School\"] == \"Harvard Business School\"),\"Bucket\"] = 1\n",
        "dfwd.loc[(df[\"School\"] == \"Ivey Business School\"),\"Bucket\"] = 3\n",
        "dfwd.loc[(df[\"School\"] == \"The Wharton School\"),\"Bucket\"] = 1\n",
        "dfwd.loc[(df[\"School\"] == \"Kellogg School of Management\"),\"Bucket\"] = 1\n",
        "dfwd.loc[(df[\"School\"] == \"Booth School of Business\"),\"Bucket\"] = 1\n",
        "dfwd.loc[(df[\"School\"] == \"Yale School of Management\"),\"Bucket\"] = 2\n",
        "dfwd.loc[(df[\"School\"] == \"NYU Stern School of Business\"),\"Bucket\"] = 2\n",
        "dfwd.loc[(df[\"School\"] == \"Tepper School of Business\"),\"Bucket\"] = 3\n",
        "dfwd.loc[(df[\"School\"] == \"UNC Kenan-Flagler Business School\"),\"Bucket\"] = 3\n",
        "dfwd.loc[(df[\"School\"] == \"The University of Texas at Austin - Red McCombs School of Business\"),\"Bucket\"] = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVK7tZgxZw_Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "outputId": "0fb0faf6-e046-4c0a-e54b-8f8c1ea94220"
      },
      "source": [
        "dfwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>M_0</th>\n",
              "      <th>M_Commerce</th>\n",
              "      <th>M_Engineering</th>\n",
              "      <th>M_University</th>\n",
              "      <th>B_0</th>\n",
              "      <th>B_Commerce</th>\n",
              "      <th>B_Engineering</th>\n",
              "      <th>B_Law</th>\n",
              "      <th>B_Management</th>\n",
              "      <th>B_Other</th>\n",
              "      <th>B_University</th>\n",
              "      <th>TotalWorkExp</th>\n",
              "      <th>Swtich</th>\n",
              "      <th>BachTier</th>\n",
              "      <th>MBA_req_1</th>\n",
              "      <th>School</th>\n",
              "      <th>MasterTier</th>\n",
              "      <th>Bucket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4107</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2804</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1918</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1461</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2495</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Columbia Business School</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1065</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2375</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1765</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2952</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1403</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYU Stern School of Business</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>998 rows Ã— 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      M_0  M_Commerce  ...  MasterTier  Bucket\n",
              "0       1           0  ...         0.0       1\n",
              "1       1           0  ...         0.0       1\n",
              "2       1           0  ...         1.0       1\n",
              "3       0           1  ...         1.0       1\n",
              "4       1           0  ...         1.0       1\n",
              "...   ...         ...  ...         ...     ...\n",
              "1063    1           0  ...         0.0       2\n",
              "1064    1           0  ...         0.0       2\n",
              "1065    1           0  ...         0.0       2\n",
              "1066    1           0  ...         0.0       2\n",
              "1067    1           0  ...         0.0       2\n",
              "\n",
              "[998 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTQDTVw3T5d1"
      },
      "source": [
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials as GC\n",
        "gc = gspread.authorize(GC.get_application_default())\n",
        "# create, and save df\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "title = 'allrevdata'\n",
        "gc.create(title)  # if not exist\n",
        "sheet = gc.open(title).sheet1\n",
        "set_with_dataframe(sheet, dfwd)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPs_MIfTQE6A"
      },
      "source": [
        "dfwd = dfwd.drop([\"School\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ymKVA8g67kC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e58765a9-458d-43a5-80dc-6937d6b8d55e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.externals import joblib\n",
        "print('Libraries Imported')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Libraries Imported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LujT-Quc_Cmo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f548713f-58a7-4b00-dd44-3fd1257b7087"
      },
      "source": [
        "#Creating the dependent variable class\n",
        "factor = pd.factorize(dfwd['Bucket'])\n",
        "dfwd.Bucket = factor[0]\n",
        "definitions = factor[1]\n",
        "print(dfwd.Bucket.head())\n",
        "print(definitions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: Bucket, dtype: int64\n",
            "Int64Index([0, 1, 2], dtype='int64')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwHiInUI_XdS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1ff26b40-cc2a-457c-fec3-3d8b0eaead49"
      },
      "source": [
        "dfwd.Bucket.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    512\n",
              "1    330\n",
              "2    156\n",
              "Name: Bucket, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNqdfoR2In2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cf5d6390-03eb-493a-d846-4b2ff36ae5cf"
      },
      "source": [
        "print(dfwd.drop([\"Bucket\"], axis=1).shape)\n",
        "dfwd[\"Bucket\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(998, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(998,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ3EHfS-IjdJ"
      },
      "source": [
        "X = dfwd.drop([\"Bucket\"], axis=1)\n",
        "y = dfwd[\"Bucket\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3T02licAWeN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "fbe868f1-1c97-4839-dafa-06d5131b9fc7"
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "classifier = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 42)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R642enMvA5dQ"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "#Reverse factorize (converting y_pred from 0s,1s and 2s to Iris-setosa, Iris-versicolor and Iris-virginica\n",
        "reversefactor = dict(zip(range(6),definitions))\n",
        "y_test = np.vectorize(reversefactor.get)(y_test)\n",
        "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
        "# Making the Confusion Matrix\n",
        "# print(pd.crosstab(y_test, y_pred, rownames=['Actual School'], colnames=['Predicted School']))\n",
        "temp = pd.DataFrame()\n",
        "temp[\"Actual School\"] = y_test\n",
        "temp[\"Predicted School\"] = y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G98Uu_OHDemZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "42448e9f-ef53-493b-986d-09dfee4893ba"
      },
      "source": [
        "print(temp.shape)\n",
        "temp[temp[\"Actual School\"] == temp[\"Predicted School\"]].shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(250, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(113, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCs4k5EI1XxU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnmQtbkHGe47"
      },
      "source": [
        "# from sklearn.datasets import fetch_mldata\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOOS4Fr-GYEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2af00f31-e6e7-4613-f0b6-53df76babc36"
      },
      "source": [
        "train_img, test_img, train_lbl, test_lbl = train_test_split(\n",
        "    X, y, test_size=1/7.0, random_state=122)\n",
        "# scaler = StandardScaler()\n",
        "# # Fit on training set only.\n",
        "# scaler.fit(train_img)\n",
        "# # Apply transform to both the training set and the test set.\n",
        "# train_img = scaler.transform(train_img)\n",
        "# test_img = scaler.transform(test_img)\n",
        "# print(np.arange(0,1,5))\n",
        "\n",
        "model = LogisticRegression(solver = 'lbfgs',C=0.1, max_iter=200)\n",
        "# model = LogisticRegression(solver = 'liblinear',C=0.1, max_iter=200,penalty=\"l2\")\n",
        "\n",
        "model.fit(train_img, train_lbl)\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)\n",
        "# use the model to make predictions with the test data\n",
        "y_pred = model.predict(test_img)\n",
        "# how did our model perform?\n",
        "count_misclassified = (test_lbl != y_pred).sum()\n",
        "print('Misclassified samples: {}'.format(count_misclassified))\n",
        "accuracy = metrics.accuracy_score(test_lbl, y_pred)\n",
        "print('Accuracy: {:.2f}'.format(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 62\n",
            "Accuracy: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r1NhIdJ-87N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "70ab8c52-85d4-40e7-a883-d9c9a11ce670"
      },
      "source": [
        "np.arange(0,1,5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2d853c07e533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdOyyibRG53u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "79cb8afb-cce6-4dbc-8ca2-a068655a65b4"
      },
      "source": [
        "# use the model to make predictions with the test data\n",
        "y_pred = model.predict(test_img)\n",
        "# how did our model perform?\n",
        "count_misclassified = (test_lbl != y_pred).sum()\n",
        "print('Misclassified samples: {}'.format(count_misclassified))\n",
        "accuracy = metrics.accuracy_score(test_lbl, y_pred)\n",
        "print('Accuracy: {:.2f}'.format(accuracy))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 62\n",
            "Accuracy: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjJDMAWTsmgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d731e50-488c-4c4e-efb5-67ca4a5e36ae"
      },
      "source": [
        "len(X.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3qGzylHHrB1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6952fd7-1eb8-4480-95a8-7968197ac898"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=16, activation='relu'))\n",
        "model.add(Dense(14, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=50, batch_size=10)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 1.3176 - accuracy: 0.4208\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.9822 - accuracy: 0.4339\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.3878 - accuracy: 0.3527\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 5.4396 - accuracy: 0.3307\n",
            "32/32 [==============================] - 0s 885us/step - loss: 5.4396 - accuracy: 0.3307\n",
            "Accuracy: 33.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY7Ap2gCrea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "835cfc83-6cf4-4fbc-98c5-0dc80c1ea137"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import metrics\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=16, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(14, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(6, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=[metrics.MeanSquaredError()])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10)\n",
        "# evaluate the keras model\n",
        "_, mse = model.evaluate(X_test, y_test)\n",
        "print('mse: %.2f' % (mse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.7389 - mean_squared_error: 0.7389\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.6117 - mean_squared_error: 0.6117\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 0s 959us/step - loss: 0.6001 - mean_squared_error: 0.6001\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 0s 995us/step - loss: 0.5988 - mean_squared_error: 0.5988\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5924 - mean_squared_error: 0.5924\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5860 - mean_squared_error: 0.5860\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5925 - mean_squared_error: 0.5925\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5834 - mean_squared_error: 0.5834\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5798 - mean_squared_error: 0.5798\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5736 - mean_squared_error: 0.5736\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 0s 997us/step - loss: 0.5703 - mean_squared_error: 0.5703\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5679 - mean_squared_error: 0.5679\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 0s 985us/step - loss: 0.5670 - mean_squared_error: 0.5670\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5672 - mean_squared_error: 0.5672\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5639 - mean_squared_error: 0.5639\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5610 - mean_squared_error: 0.5610\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 0s 988us/step - loss: 0.5587 - mean_squared_error: 0.5587\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 0s 989us/step - loss: 0.5579 - mean_squared_error: 0.5579\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 0s 979us/step - loss: 0.5581 - mean_squared_error: 0.5581\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5572 - mean_squared_error: 0.5572\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5560 - mean_squared_error: 0.5560\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 0s 970us/step - loss: 0.5571 - mean_squared_error: 0.5571\n",
            "Epoch 23/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5549 - mean_squared_error: 0.5549\n",
            "Epoch 24/100\n",
            "75/75 [==============================] - 0s 999us/step - loss: 0.5551 - mean_squared_error: 0.5551\n",
            "Epoch 25/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5537 - mean_squared_error: 0.5537\n",
            "Epoch 26/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5533 - mean_squared_error: 0.5533\n",
            "Epoch 27/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5520 - mean_squared_error: 0.5520\n",
            "Epoch 28/100\n",
            "75/75 [==============================] - 0s 966us/step - loss: 0.5544 - mean_squared_error: 0.5544\n",
            "Epoch 29/100\n",
            "75/75 [==============================] - 0s 964us/step - loss: 0.5525 - mean_squared_error: 0.5525\n",
            "Epoch 30/100\n",
            "75/75 [==============================] - 0s 994us/step - loss: 0.5516 - mean_squared_error: 0.5516\n",
            "Epoch 31/100\n",
            "75/75 [==============================] - 0s 997us/step - loss: 0.5517 - mean_squared_error: 0.5517\n",
            "Epoch 32/100\n",
            "75/75 [==============================] - 0s 938us/step - loss: 0.5517 - mean_squared_error: 0.5517\n",
            "Epoch 33/100\n",
            "75/75 [==============================] - 0s 991us/step - loss: 0.5505 - mean_squared_error: 0.5505\n",
            "Epoch 34/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5515 - mean_squared_error: 0.5515\n",
            "Epoch 35/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5509 - mean_squared_error: 0.5509\n",
            "Epoch 36/100\n",
            "75/75 [==============================] - 0s 984us/step - loss: 0.5522 - mean_squared_error: 0.5522\n",
            "Epoch 37/100\n",
            "75/75 [==============================] - 0s 1000us/step - loss: 0.5512 - mean_squared_error: 0.5512\n",
            "Epoch 38/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5514 - mean_squared_error: 0.5514\n",
            "Epoch 39/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5496 - mean_squared_error: 0.5496\n",
            "Epoch 40/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5528 - mean_squared_error: 0.5528\n",
            "Epoch 41/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5510 - mean_squared_error: 0.5510\n",
            "Epoch 42/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5504 - mean_squared_error: 0.5504\n",
            "Epoch 43/100\n",
            "75/75 [==============================] - 0s 980us/step - loss: 0.5517 - mean_squared_error: 0.5517\n",
            "Epoch 44/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5505 - mean_squared_error: 0.5505\n",
            "Epoch 45/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5501 - mean_squared_error: 0.5501\n",
            "Epoch 46/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5513 - mean_squared_error: 0.5513\n",
            "Epoch 47/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5502 - mean_squared_error: 0.5502\n",
            "Epoch 48/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5496 - mean_squared_error: 0.5496\n",
            "Epoch 49/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5499 - mean_squared_error: 0.5499\n",
            "Epoch 50/100\n",
            "75/75 [==============================] - 0s 959us/step - loss: 0.5496 - mean_squared_error: 0.5496\n",
            "Epoch 51/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5511 - mean_squared_error: 0.5511\n",
            "Epoch 52/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5513 - mean_squared_error: 0.5513\n",
            "Epoch 53/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5514 - mean_squared_error: 0.5514\n",
            "Epoch 54/100\n",
            "75/75 [==============================] - 0s 982us/step - loss: 0.5493 - mean_squared_error: 0.5493\n",
            "Epoch 55/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5496 - mean_squared_error: 0.5496\n",
            "Epoch 56/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5505 - mean_squared_error: 0.5505\n",
            "Epoch 57/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5507 - mean_squared_error: 0.5507\n",
            "Epoch 58/100\n",
            "75/75 [==============================] - 0s 981us/step - loss: 0.5508 - mean_squared_error: 0.5508\n",
            "Epoch 59/100\n",
            "75/75 [==============================] - 0s 974us/step - loss: 0.5496 - mean_squared_error: 0.5496\n",
            "Epoch 60/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5507 - mean_squared_error: 0.5507\n",
            "Epoch 61/100\n",
            "75/75 [==============================] - 0s 976us/step - loss: 0.5508 - mean_squared_error: 0.5508\n",
            "Epoch 62/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5502 - mean_squared_error: 0.5502\n",
            "Epoch 63/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5501 - mean_squared_error: 0.5501\n",
            "Epoch 64/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5500 - mean_squared_error: 0.5500\n",
            "Epoch 65/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5497 - mean_squared_error: 0.5497\n",
            "Epoch 66/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5507 - mean_squared_error: 0.5507\n",
            "Epoch 67/100\n",
            "75/75 [==============================] - 0s 998us/step - loss: 0.5495 - mean_squared_error: 0.5495\n",
            "Epoch 68/100\n",
            "75/75 [==============================] - 0s 963us/step - loss: 0.5515 - mean_squared_error: 0.5515\n",
            "Epoch 69/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5505 - mean_squared_error: 0.5505\n",
            "Epoch 70/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5490 - mean_squared_error: 0.5490\n",
            "Epoch 71/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5500 - mean_squared_error: 0.5500\n",
            "Epoch 72/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5497 - mean_squared_error: 0.5497\n",
            "Epoch 73/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5486 - mean_squared_error: 0.5486\n",
            "Epoch 74/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5505 - mean_squared_error: 0.5505\n",
            "Epoch 75/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5496 - mean_squared_error: 0.5496\n",
            "Epoch 76/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5502 - mean_squared_error: 0.5502\n",
            "Epoch 77/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5492 - mean_squared_error: 0.5492\n",
            "Epoch 78/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5488 - mean_squared_error: 0.5488\n",
            "Epoch 79/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5501 - mean_squared_error: 0.5501\n",
            "Epoch 80/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5508 - mean_squared_error: 0.5508\n",
            "Epoch 81/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5521 - mean_squared_error: 0.5521\n",
            "Epoch 82/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5521 - mean_squared_error: 0.5521\n",
            "Epoch 83/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5488 - mean_squared_error: 0.5488\n",
            "Epoch 84/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5492 - mean_squared_error: 0.5492\n",
            "Epoch 85/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5489 - mean_squared_error: 0.5489\n",
            "Epoch 86/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5502 - mean_squared_error: 0.5502\n",
            "Epoch 87/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5499 - mean_squared_error: 0.5499\n",
            "Epoch 88/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5483 - mean_squared_error: 0.5483\n",
            "Epoch 89/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5474 - mean_squared_error: 0.5474\n",
            "Epoch 90/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5517 - mean_squared_error: 0.5517\n",
            "Epoch 91/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5497 - mean_squared_error: 0.5497\n",
            "Epoch 92/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5507 - mean_squared_error: 0.5507\n",
            "Epoch 93/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5492 - mean_squared_error: 0.5492\n",
            "Epoch 94/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5487 - mean_squared_error: 0.5487\n",
            "Epoch 95/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5439 - mean_squared_error: 0.5439\n",
            "Epoch 96/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5483 - mean_squared_error: 0.5483\n",
            "Epoch 97/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5466 - mean_squared_error: 0.5466\n",
            "Epoch 98/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5502 - mean_squared_error: 0.5502\n",
            "Epoch 99/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5512 - mean_squared_error: 0.5512\n",
            "Epoch 100/100\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 0.5484 - mean_squared_error: 0.5484\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5095 - mean_squared_error: 0.5095\n",
            "mse: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbfZEKDZbm6k"
      },
      "source": [
        "**KNN**\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvyQxrkNH9gP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "98e9e789-6f5f-4321-8684-973a92f974e6"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y = df['School'].astype(str)\n",
        "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X, y, test_size=0.05, random_state=2000)\n",
        "for i in range(1,20):\n",
        "  neigh = KNeighborsClassifier(n_neighbors=i)\n",
        "  neigh.fit(X_train_n, y_train_n)\n",
        "  pred = neigh.predict(X_test_n)\n",
        "\n",
        "  print(i,accuracy_score(y_test_n, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.1935483870967742\n",
            "2 0.12903225806451613\n",
            "3 0.1935483870967742\n",
            "4 0.1935483870967742\n",
            "5 0.25806451612903225\n",
            "6 0.16129032258064516\n",
            "7 0.1935483870967742\n",
            "8 0.12903225806451613\n",
            "9 0.12903225806451613\n",
            "10 0.12903225806451613\n",
            "11 0.12903225806451613\n",
            "12 0.12903225806451613\n",
            "13 0.1935483870967742\n",
            "14 0.1935483870967742\n",
            "15 0.22580645161290322\n",
            "16 0.16129032258064516\n",
            "17 0.12903225806451613\n",
            "18 0.16129032258064516\n",
            "19 0.0967741935483871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gi1sAR5I6is"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsoUPDgwfgQF"
      },
      "source": [
        "# import gspread\n",
        "# from oauth2client.client import GoogleCredentials as GC\n",
        "# gc = gspread.authorize(GC.get_application_default())\n",
        "# # create, and save df\n",
        "# from gspread_dataframe import set_with_dataframe\n",
        "# title = 'CheckAllschool'\n",
        "# gc.create(title)  # if not exist\n",
        "# sheet = gc.open(title).sheet1\n",
        "# set_with_dataframe(sheet, df_final)\n",
        "# df = pd.read_csv(\"ImpAllschool - Sheet1.csv\")\n",
        "# df1 = df.drop(['Full name'], axis = 1)\n",
        "# df_final = pd.concat((pd.get_dummies(df_final['BachDegree'], prefix = 'B'), df_final), axis = 1).drop(['BachDegree'], axis = 1)\n",
        "# df_final = pd.concat((pd.get_dummies(df_final['MasterDegree'], prefix = 'M'), df_final), axis = 1).drop(['MasterDegree'], axis = 1)\n",
        "# df_final = pd.concat((pd.get_dummies(df_final['MBADegree'], prefix = \"MBA\"), df_final), axis = 1).drop(['MBADegree'], axis = 1)\n",
        "\n",
        "# # df1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e9f1hBJVhs2"
      },
      "source": [
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# vectorizer = CountVectorizer()\n",
        "# X = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBRZTmweVuv6"
      },
      "source": [
        "# # vectorizer.fit_transform(df_final['BachDegree'][0])\n",
        "# # vectorizer.fit_transform(df_final['BachDegree'].tolist())\n",
        "\n",
        "# vectorizer.fit_transform(df_final['BachDegree'].astype(str)).toarray()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX7sUrW6Vuz1"
      },
      "source": [
        "# df_final=df.drop(columns=['Total Exp',\"MBA_tier\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMy8HV8GeZv8"
      },
      "source": [
        "y = df_final[\"School Rank\"]\n",
        "X = df_final.drop([\"School Rank\"], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBCEJGds0aMK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "284cbd86-42ae-4d52-fcc7-4975dce55a88"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCUT07Zle4A9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO9ifPLhfPDX"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "# clf = LinearRegression()\n",
        "# clf.fit(X_train, y_train)\n",
        "# pred = clf.predict(X_test)\n",
        "# # new = pd.DataFrame()\n",
        "# # new['pred'] = pred\n",
        "# # new['orig'] = y_test\n",
        "# new = pd.DataFrame(np.array([np.array(y_test),pred])).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr3r8VBNf2Ox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dc84727-d23b-4254-bfb5-29da6d5ae28c"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_test, pred, squared=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.80812488095258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tejIETgFf5eZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "b1754d36-0a85-44a3-d386-13d0e1040517"
      },
      "source": [
        "new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.0</td>\n",
              "      <td>10.882609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>6.755339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.0</td>\n",
              "      <td>13.557923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.273310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.0</td>\n",
              "      <td>12.816439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.301782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>8.0</td>\n",
              "      <td>3.666195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.252333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.932839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>1.0</td>\n",
              "      <td>6.496023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>134 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0          1\n",
              "0    20.0  10.882609\n",
              "1     1.0   6.755339\n",
              "2    20.0  13.557923\n",
              "3     1.0   5.273310\n",
              "4    20.0  12.816439\n",
              "..    ...        ...\n",
              "129   1.0   5.301782\n",
              "130   8.0   3.666195\n",
              "131   1.0   3.252333\n",
              "132   1.0   3.932839\n",
              "133   1.0   6.496023\n",
              "\n",
              "[134 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20BnTTF0iG1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "36172874-5cf9-40a2-83e3-8ab1536fba7f"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y = df['School'].astype(str)\n",
        "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X, y, test_size=0.05, random_state=2000)\n",
        "for i in range(1,20):\n",
        "  neigh = KNeighborsClassifier(n_neighbors=i)\n",
        "  neigh.fit(X_train_n, y_train_n)\n",
        "  pred = neigh.predict(X_test_n)\n",
        "\n",
        "  print(i,accuracy_score(y_test_n, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.2647058823529412\n",
            "2 0.08823529411764706\n",
            "3 0.20588235294117646\n",
            "4 0.29411764705882354\n",
            "5 0.23529411764705882\n",
            "6 0.3235294117647059\n",
            "7 0.2647058823529412\n",
            "8 0.2647058823529412\n",
            "9 0.2647058823529412\n",
            "10 0.23529411764705882\n",
            "11 0.17647058823529413\n",
            "12 0.20588235294117646\n",
            "13 0.2647058823529412\n",
            "14 0.29411764705882354\n",
            "15 0.3235294117647059\n",
            "16 0.23529411764705882\n",
            "17 0.23529411764705882\n",
            "18 0.2647058823529412\n",
            "19 0.29411764705882354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5lb5zAqi-v0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1SEfHadjKMP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9e8574f9-e78f-4b93-a915-698b2de7d410"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJttl6ucjeut"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp-7tY9mjjAN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8673189-96e0-40c5-b9d7-1e0738fcb5a1"
      },
      "source": [
        "pd.DataFrame(np.array([pred, np.array(y_test_n)])).transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>CBS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>CBS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Ivey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Booth</td>\n",
              "      <td>Booth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Booth</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Booth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ivey</td>\n",
              "      <td>Ivey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Ivey</td>\n",
              "      <td>Ivey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>CBS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Booth</td>\n",
              "      <td>Kelogg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Ivey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Ivey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Booth</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Ivey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>HBS</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>HBS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>HBS</td>\n",
              "      <td>HBS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>HBS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Booth</td>\n",
              "      <td>Booth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Booth</td>\n",
              "      <td>Booth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>HBS</td>\n",
              "      <td>Booth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Kelogg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Ivey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Wharton</td>\n",
              "      <td>Wharton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0        1\n",
              "0   Wharton      CBS\n",
              "1   Wharton      CBS\n",
              "2   Wharton     Ivey\n",
              "3   Wharton  Wharton\n",
              "4     Booth    Booth\n",
              "5     Booth  Wharton\n",
              "6   Wharton    Booth\n",
              "7   Wharton  Wharton\n",
              "8   Wharton  Wharton\n",
              "9      Ivey     Ivey\n",
              "10     Ivey     Ivey\n",
              "11  Wharton      CBS\n",
              "12  Wharton  Wharton\n",
              "13    Booth   Kelogg\n",
              "14  Wharton  Wharton\n",
              "15  Wharton     Ivey\n",
              "16  Wharton     Ivey\n",
              "17    Booth  Wharton\n",
              "18  Wharton     Ivey\n",
              "19      HBS  Wharton\n",
              "20  Wharton      HBS\n",
              "21      HBS      HBS\n",
              "22  Wharton  Wharton\n",
              "23  Wharton      HBS\n",
              "24    Booth    Booth\n",
              "25    Booth    Booth\n",
              "26  Wharton  Wharton\n",
              "27      HBS    Booth\n",
              "28  Wharton  Wharton\n",
              "29  Wharton  Wharton\n",
              "30  Wharton   Kelogg\n",
              "31  Wharton     Ivey\n",
              "32  Wharton  Wharton\n",
              "33  Wharton  Wharton"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJpw5JI4jqyQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "925fd647-6a7f-47ff-d1ed-2cae45f4e696"
      },
      "source": [
        "df[\"School\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Wharton    260\n",
              "Ivey        92\n",
              "Booth       92\n",
              "Kelogg      76\n",
              "CBS         76\n",
              "HBS         71\n",
              "Name: School, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqEltW9KbhRm"
      },
      "source": [
        "y_test_n=y_test_n.map({\"CBS\":8, \"Wharton\":1, \"Booth\":3, \"Kelogg\":3, \"HBS\":6, \"Ivey\":20})\n",
        "y_train_n=y_train_n.map({\"CBS\":8, \"Wharton\":1, \"Booth\":3, \"Kelogg\":3, \"HBS\":6, \"Ivey\":20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5QaS4drkmJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56cecd2d-374e-4d37-fef0-7fdc800291ac"
      },
      "source": [
        "\n",
        "clf = LinearRegression()\n",
        "clf.fit(X_train_n, y_train_n)\n",
        "pred = clf.predict(X_test_n)\n",
        "new = pd.DataFrame(np.array([np.array(y_test_n),pred])).transpose()\n",
        "new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.0</td>\n",
              "      <td>2.813195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9.954321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.896060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.592823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.698252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.293570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.0</td>\n",
              "      <td>4.278822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.024694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.0</td>\n",
              "      <td>7.441061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.206326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20.0</td>\n",
              "      <td>13.497353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.562396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.758303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.538279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.265905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.0</td>\n",
              "      <td>11.942674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.180623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.969845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20.0</td>\n",
              "      <td>12.744815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>8.0</td>\n",
              "      <td>5.684873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.725448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.258543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.845139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.0</td>\n",
              "      <td>7.598233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>20.0</td>\n",
              "      <td>12.036091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.749256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.041659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6.0</td>\n",
              "      <td>4.230201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.959157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>8.0</td>\n",
              "      <td>4.534131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>8.0</td>\n",
              "      <td>4.967501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>20.0</td>\n",
              "      <td>12.074427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.848970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.385236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0          1\n",
              "0   20.0   2.813195\n",
              "1    1.0   9.954321\n",
              "2    1.0   3.896060\n",
              "3    3.0   3.592823\n",
              "4    3.0   2.698252\n",
              "5    6.0   2.293570\n",
              "6    6.0   4.278822\n",
              "7    1.0   3.024694\n",
              "8    6.0   7.441061\n",
              "9    6.0   1.206326\n",
              "10  20.0  13.497353\n",
              "11   1.0   1.562396\n",
              "12   1.0   1.758303\n",
              "13   3.0   1.538279\n",
              "14   1.0   3.265905\n",
              "15   3.0  11.942674\n",
              "16   1.0   5.180623\n",
              "17   1.0   2.969845\n",
              "18  20.0  12.744815\n",
              "19   8.0   5.684873\n",
              "20   1.0   4.725448\n",
              "21   6.0   3.258543\n",
              "22   3.0   2.845139\n",
              "23   6.0   7.598233\n",
              "24  20.0  12.036091\n",
              "25   1.0   3.749256\n",
              "26   1.0   5.041659\n",
              "27   6.0   4.230201\n",
              "28   1.0   3.959157\n",
              "29   8.0   4.534131\n",
              "30   8.0   4.967501\n",
              "31  20.0  12.074427\n",
              "32   1.0   3.848970\n",
              "33   6.0   3.385236"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQkEt_3tamom",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a285386-2fdc-4a31-8bb3-f77c5c159931"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_test_n, pred, squared=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.35824395085863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw4iDilxb42X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOqpy-azfmYP"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class Antirectifier(layers.Layer):\n",
        "    def __init__(self, initializer=\"he_normal\", **kwargs):\n",
        "        super(Antirectifier, self).__init__(**kwargs)\n",
        "        self.initializer = keras.initializers.get(initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        output_dim = input_shape[-1]\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(output_dim * 2, output_dim),\n",
        "            initializer=self.initializer,\n",
        "            name=\"kernel\",\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs -= tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
        "        pos = tf.nn.relu(inputs)\n",
        "        neg = tf.nn.relu(-inputs)\n",
        "        concatenated = tf.concat([pos, neg], axis=-1)\n",
        "        mixed = tf.matmul(concatenated, self.kernel)\n",
        "        return mixed\n",
        "\n",
        "    def get_config(self):\n",
        "        # Implement get_config to enable serialization. This is optional.\n",
        "        base_config = super(Antirectifier, self).get_config()\n",
        "        config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4ZFrckGf8T8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ec9aa01-43d0-437d-ad47-8b44c604bb0f"
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# The data, split between train and test sets\n",
        "# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# x_train = x_train.reshape(-1, 18)\n",
        "# x_test = x_test.reshape(-1, 18)\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# Build the model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(18,)),\n",
        "        layers.Dense(256),\n",
        "        Antirectifier(),\n",
        "        layers.Dense(256),\n",
        "        Antirectifier(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.15)\n",
        "\n",
        "# Test the model\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391 train samples\n",
            "98 test samples\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ae161e9471eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 20 which is outside the valid range of [0, 10).  Label values: 1 10 2 2 10 10 20 20 6 2 4 2 2 4 2 10 6 6 4 6 2 20 4 6 2 1 6 6 4 4 20 2 4 6 4 20 20 1 4 4 2 4 1 2 4 2 2 2 1 2 4 20 2 2 2 10 20 1 6 6 2 2 6 2 20 10 2 10 10 20 20 2 2 1 2 2 4 4 2 10 4 2 2 2 2 4 2 2 1 6 2 2 6 1 20 20 6 20 6 2 1 6 6 20 20 10 2 10 20 2 10 2 1 10 2 2 2 10 20 4 2 10 20 2 2 20 2 2\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-22-ae161e9471eb>:39) ]] [Op:__inference_train_function_1316]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjVx8iAeigdm"
      },
      "source": [
        "\n",
        "# first neural network with keras tutorial\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import metrics\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHU1-P9HpdqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14a7d00b-b808-4f01-ff75-a6334dd8e440"
      },
      "source": [
        "df_final[\"School Rank\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([20,  2,  6,  1,  4, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-86wIEljL3Z"
      },
      "source": [
        "# model = Sequential()\n",
        "y = df_final[\"School Rank\"]\n",
        "X = df_final.drop([\"School Rank\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vIi1p29tgh4"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "# clf = LinearRegression()\n",
        "# clf.fit(X_train, y_train)\n",
        "# pred = clf.predict(X_test)\n",
        "# # new = pd.DataFrame()\n",
        "# # new['pred'] = pred\n",
        "# # new['orig'] = y_test\n",
        "# new = pd.DataFrame(np.array([np.array(y_test),pred])).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgZpOKaKlYuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b79f693e-3a03-4efd-f98c-4795674d1639"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=18, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(20, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(15, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(10, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(5, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=[metrics.MeanSquaredError()])\n",
        "\n",
        "\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=20)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print('accuracy: %.2f' % (accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 0s 869us/step - loss: 81.6232 - mean_squared_error: 81.6232\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 79.7396 - mean_squared_error: 79.7396\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 60.8578 - mean_squared_error: 60.8578\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 49.3856 - mean_squared_error: 49.3856\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 0s 70us/step - loss: 47.4923 - mean_squared_error: 47.4923\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 45.7637 - mean_squared_error: 45.7637\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 0s 78us/step - loss: 45.6341 - mean_squared_error: 45.6341\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 45.7382 - mean_squared_error: 45.7382\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 47.5895 - mean_squared_error: 47.5895\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 46.9163 - mean_squared_error: 46.9163\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 45.7664 - mean_squared_error: 45.7664\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 0s 74us/step - loss: 45.9032 - mean_squared_error: 45.9032\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 0s 75us/step - loss: 45.1395 - mean_squared_error: 45.1395\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 45.5605 - mean_squared_error: 45.5605\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 0s 73us/step - loss: 45.1940 - mean_squared_error: 45.1940\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 45.0899 - mean_squared_error: 45.0899\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 0s 80us/step - loss: 44.9382 - mean_squared_error: 44.9382\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 44.8650 - mean_squared_error: 44.8650\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 44.6483 - mean_squared_error: 44.6483\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 0s 68us/step - loss: 45.1548 - mean_squared_error: 45.1548\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 0s 79us/step - loss: 44.7102 - mean_squared_error: 44.7102\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 0s 67us/step - loss: 44.7296 - mean_squared_error: 44.7296\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 0s 75us/step - loss: 44.9584 - mean_squared_error: 44.9584\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 0s 77us/step - loss: 44.8997 - mean_squared_error: 44.8997\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 0s 73us/step - loss: 44.4702 - mean_squared_error: 44.4702\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 0s 83us/step - loss: 44.5244 - mean_squared_error: 44.5244\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 0s 112us/step - loss: 44.4230 - mean_squared_error: 44.4230\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 0s 104us/step - loss: 44.6552 - mean_squared_error: 44.6552\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 0s 106us/step - loss: 44.1469 - mean_squared_error: 44.1469\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 0s 110us/step - loss: 44.2900 - mean_squared_error: 44.2900\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 0s 82us/step - loss: 44.3406 - mean_squared_error: 44.3406\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 0s 79us/step - loss: 43.8851 - mean_squared_error: 43.8851\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 0s 85us/step - loss: 44.3027 - mean_squared_error: 44.3027\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 0s 85us/step - loss: 44.1343 - mean_squared_error: 44.1343\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 0s 87us/step - loss: 44.0244 - mean_squared_error: 44.0244\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 0s 85us/step - loss: 43.9046 - mean_squared_error: 43.9046\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 0s 87us/step - loss: 45.3233 - mean_squared_error: 45.3233\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 0s 86us/step - loss: 45.5172 - mean_squared_error: 45.5172\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 0s 82us/step - loss: 44.0298 - mean_squared_error: 44.0298\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 0s 93us/step - loss: 43.6485 - mean_squared_error: 43.6485\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 0s 87us/step - loss: 43.8340 - mean_squared_error: 43.8340\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 0s 87us/step - loss: 44.4615 - mean_squared_error: 44.4615\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 0s 86us/step - loss: 43.8716 - mean_squared_error: 43.8716\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 0s 85us/step - loss: 43.7730 - mean_squared_error: 43.7730\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 0s 86us/step - loss: 43.2785 - mean_squared_error: 43.2785\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 0s 76us/step - loss: 43.8156 - mean_squared_error: 43.8156\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 0s 68us/step - loss: 43.7108 - mean_squared_error: 43.7108\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 0s 75us/step - loss: 43.4747 - mean_squared_error: 43.4747\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 43.1580 - mean_squared_error: 43.1581\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 0s 87us/step - loss: 43.3543 - mean_squared_error: 43.3543\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 0s 87us/step - loss: 43.1578 - mean_squared_error: 43.1578\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 43.9478 - mean_squared_error: 43.9478\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 0s 75us/step - loss: 42.6541 - mean_squared_error: 42.6541\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 0s 70us/step - loss: 43.1709 - mean_squared_error: 43.1709\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 43.4631 - mean_squared_error: 43.4631\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 43.1942 - mean_squared_error: 43.1942\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 0s 84us/step - loss: 42.6530 - mean_squared_error: 42.6530\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 0s 90us/step - loss: 43.5527 - mean_squared_error: 43.5527\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 0s 90us/step - loss: 42.7823 - mean_squared_error: 42.7823\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 0s 101us/step - loss: 42.6259 - mean_squared_error: 42.6259\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 0s 88us/step - loss: 42.4589 - mean_squared_error: 42.4589\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 0s 84us/step - loss: 42.2070 - mean_squared_error: 42.2070\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 0s 82us/step - loss: 42.3439 - mean_squared_error: 42.3438\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 0s 82us/step - loss: 42.3362 - mean_squared_error: 42.3362\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 0s 83us/step - loss: 42.7884 - mean_squared_error: 42.7884\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 0s 88us/step - loss: 42.2607 - mean_squared_error: 42.2607\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 0s 91us/step - loss: 42.1352 - mean_squared_error: 42.1352\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 0s 87us/step - loss: 42.1115 - mean_squared_error: 42.1115\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 0s 86us/step - loss: 42.3075 - mean_squared_error: 42.3075\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 0s 88us/step - loss: 42.1535 - mean_squared_error: 42.1535\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 0s 83us/step - loss: 41.9348 - mean_squared_error: 41.9348\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 0s 90us/step - loss: 42.1239 - mean_squared_error: 42.1239\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 0s 89us/step - loss: 42.1284 - mean_squared_error: 42.1284\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 0s 85us/step - loss: 41.9094 - mean_squared_error: 41.9094\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 0s 83us/step - loss: 41.8601 - mean_squared_error: 41.8601\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 0s 75us/step - loss: 41.8257 - mean_squared_error: 41.8257\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 41.9349 - mean_squared_error: 41.9349\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 0s 73us/step - loss: 41.9543 - mean_squared_error: 41.9543\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 0s 68us/step - loss: 41.5340 - mean_squared_error: 41.5340\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 41.7790 - mean_squared_error: 41.7790\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 41.5637 - mean_squared_error: 41.5637\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 0s 82us/step - loss: 41.6107 - mean_squared_error: 41.6107\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 0s 74us/step - loss: 41.7310 - mean_squared_error: 41.7310\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 0s 76us/step - loss: 41.6131 - mean_squared_error: 41.6131\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 41.4276 - mean_squared_error: 41.4276\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 0s 78us/step - loss: 41.3312 - mean_squared_error: 41.3312\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 41.5468 - mean_squared_error: 41.5468\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 0s 66us/step - loss: 41.2893 - mean_squared_error: 41.2893\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 0s 77us/step - loss: 41.2135 - mean_squared_error: 41.2135\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 0s 78us/step - loss: 41.5233 - mean_squared_error: 41.5233\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 0s 69us/step - loss: 41.1118 - mean_squared_error: 41.1118\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 0s 77us/step - loss: 41.2994 - mean_squared_error: 41.2994\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 41.3410 - mean_squared_error: 41.3410\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 0s 70us/step - loss: 41.1971 - mean_squared_error: 41.1971\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 0s 73us/step - loss: 40.8567 - mean_squared_error: 40.8567\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 0s 76us/step - loss: 41.1464 - mean_squared_error: 41.1464\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 0s 72us/step - loss: 41.3636 - mean_squared_error: 41.3636\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 0s 71us/step - loss: 40.9629 - mean_squared_error: 40.9629\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 0s 70us/step - loss: 41.0481 - mean_squared_error: 41.0481\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 0s 67us/step - loss: 41.0861 - mean_squared_error: 41.0861\n",
            "98/98 [==============================] - 0s 273us/step\n",
            "accuracy: 44.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRBKBhjCl-fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "aa7786bf-6dbd-4c9b-ea4e-5a38932c44d5"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y = df['School Rank'].astype(str)\n",
        "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X, y, test_size=0.05, random_state=2000)\n",
        "for i in range(1,20):\n",
        "  neigh = KNeighborsClassifier(n_neighbors=i)\n",
        "  neigh.fit(X_train_n, y_train_n)\n",
        "  pred = neigh.predict(X_test_n)\n",
        "\n",
        "  print(i,accuracy_score(y_test_n, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.16\n",
            "2 0.28\n",
            "3 0.28\n",
            "4 0.44\n",
            "5 0.32\n",
            "6 0.36\n",
            "7 0.32\n",
            "8 0.32\n",
            "9 0.36\n",
            "10 0.36\n",
            "11 0.32\n",
            "12 0.28\n",
            "13 0.36\n",
            "14 0.36\n",
            "15 0.32\n",
            "16 0.32\n",
            "17 0.28\n",
            "18 0.28\n",
            "19 0.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygMJ-9MGuMsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "d2d6d38e-7795-429a-f715-c43d0d39cdcc"
      },
      "source": [
        "df_final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>M_Commerce</th>\n",
              "      <th>M_Engineering</th>\n",
              "      <th>M_University</th>\n",
              "      <th>B_Commerce</th>\n",
              "      <th>B_Engineering</th>\n",
              "      <th>B_Law</th>\n",
              "      <th>B_Management</th>\n",
              "      <th>B_Other</th>\n",
              "      <th>B_University</th>\n",
              "      <th>Tier1Exp</th>\n",
              "      <th>Tier2Exp</th>\n",
              "      <th>Tier3Exp</th>\n",
              "      <th>Tier4Exp</th>\n",
              "      <th>Tier5Exp</th>\n",
              "      <th>Swtich</th>\n",
              "      <th>BachTier</th>\n",
              "      <th>MasterTier</th>\n",
              "      <th>MBA_req_1</th>\n",
              "      <th>School Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2345</td>\n",
              "      <td>517</td>\n",
              "      <td>518</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1277</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4383</td>\n",
              "      <td>0</td>\n",
              "      <td>1096</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1430</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>731</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>730</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3653</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>396</td>\n",
              "      <td>0</td>\n",
              "      <td>1004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1672</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>822</td>\n",
              "      <td>1155</td>\n",
              "      <td>1065</td>\n",
              "      <td>0</td>\n",
              "      <td>671</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>489 rows Ã— 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     M_Commerce  M_Engineering  ...  MBA_req_1  School Rank\n",
              "0             0              0  ...          0           20\n",
              "1             0              1  ...          0            2\n",
              "2             0              1  ...          0            6\n",
              "3             0              1  ...          0            2\n",
              "4             0              0  ...          1            2\n",
              "..          ...            ...  ...        ...          ...\n",
              "484           0              0  ...          0            1\n",
              "485           0              0  ...          0            2\n",
              "486           0              0  ...          0            2\n",
              "487           0              0  ...          0            2\n",
              "488           0              0  ...          0            4\n",
              "\n",
              "[489 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKGEfSbMxjA3"
      },
      "source": [
        "df_final_1 = pd.concat((pd.get_dummies(df['School Rank'], prefix = 'R'), df), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YvSggXHxtrX"
      },
      "source": [
        "df_final_1 = df_final_1.drop([\"School Rank\"], axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sdl3FeszAcj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "a99782ce-9db2-44b6-9539-029a722ed07b"
      },
      "source": [
        "df_final_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R_1</th>\n",
              "      <th>R_2</th>\n",
              "      <th>R_4</th>\n",
              "      <th>R_6</th>\n",
              "      <th>R_10</th>\n",
              "      <th>R_20</th>\n",
              "      <th>M_Commerce</th>\n",
              "      <th>M_Engineering</th>\n",
              "      <th>M_University</th>\n",
              "      <th>B_Commerce</th>\n",
              "      <th>B_Engineering</th>\n",
              "      <th>B_Law</th>\n",
              "      <th>B_Management</th>\n",
              "      <th>B_Other</th>\n",
              "      <th>B_University</th>\n",
              "      <th>Tier1Exp</th>\n",
              "      <th>Tier2Exp</th>\n",
              "      <th>Tier3Exp</th>\n",
              "      <th>Tier4Exp</th>\n",
              "      <th>Tier5Exp</th>\n",
              "      <th>Total Exp</th>\n",
              "      <th>Swtich</th>\n",
              "      <th>BachTier</th>\n",
              "      <th>MasterTier</th>\n",
              "      <th>MBA_tier</th>\n",
              "      <th>MBA_req_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2345</td>\n",
              "      <td>517</td>\n",
              "      <td>518</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3380</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1277</td>\n",
              "      <td>8246</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4383</td>\n",
              "      <td>0</td>\n",
              "      <td>1096</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5479</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1430</td>\n",
              "      <td>1430</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>731</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1096</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>730</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>730</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3653</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3653</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>396</td>\n",
              "      <td>0</td>\n",
              "      <td>1004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1400</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1672</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1672</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>822</td>\n",
              "      <td>1155</td>\n",
              "      <td>1065</td>\n",
              "      <td>0</td>\n",
              "      <td>671</td>\n",
              "      <td>3713</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>489 rows Ã— 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     R_1  R_2  R_4  R_6  ...  BachTier  MasterTier  MBA_tier  MBA_req_1\n",
              "0      0    0    0    0  ...         1           1         1          0\n",
              "1      0    1    0    0  ...         5           1         1          0\n",
              "2      0    0    0    1  ...         1           1         1          0\n",
              "3      0    1    0    0  ...         2           1         1          0\n",
              "4      0    1    0    0  ...         1           0         1          1\n",
              "..   ...  ...  ...  ...  ...       ...         ...       ...        ...\n",
              "484    1    0    0    0  ...         1           0         1          0\n",
              "485    0    1    0    0  ...         1           0         1          0\n",
              "486    0    1    0    0  ...         1           0         1          0\n",
              "487    0    1    0    0  ...         1           0         1          0\n",
              "488    0    0    1    0  ...         1           0         1          0\n",
              "\n",
              "[489 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EeLfxIcy3f1"
      },
      "source": [
        "df_final_y_1 = df_final_1[\"R_1\"]\n",
        "df_final_x_1 = df_final_1.drop([\"R_1\",\"R_2\",\"R_6\",\"R_20\",\"R_4\",\"R_10\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJopxMzZ0zYf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "740a30f5-c0a0-40bc-f687-2a8fa6d381ec"
      },
      "source": [
        "df_final_x_1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(489, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id8f1aNbx1QJ"
      },
      "source": [
        "X_train_d1, X_test_d1, y_train_d1, y_test_d1 = train_test_split(df_final_x_1, df_final_y_1, test_size=0.05, random_state=2000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6prboH4zZVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "700f8c62-22a9-49fe-af2e-fcd4e420e956"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "from imblearn.keras import balanced_batch_generator\n",
        "from imblearn.under_sampling import NearMiss\n",
        "training_generator, steps_per_epoch = balanced_batch_generator(X_train_d1, y_train_d1, sampler=NearMiss(), batch_size=10, random_state=42)\n",
        "callback_history = model.fit_generator(generator=training_generator,steps_per_epoch=steps_per_epoch,epochs=100, verbose=0)\n",
        "\n",
        "# # fit the keras model on the dataset\n",
        "# model.fit(X_train_d1, y_train_d1, epochs=100, batch_size=20)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_test_d1, y_test_d1)\n",
        "print('accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r25/25 [==============================] - 0s 730us/step\n",
            "accuracy: 88.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GgIXyBb0tED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "181644f6-7275-46d1-c6c2-4cb837c720af"
      },
      "source": [
        "df_final_y_2 = df_final_1[\"R_2\"]\n",
        "df_final_x_2 = df_final_1.drop([\"R_1\",\"R_2\",\"R_6\",\"R_20\",\"R_4\",\"R_10\"], axis=1)\n",
        "X_train_d2, X_test_d2, y_train_d2, y_test_d2 = train_test_split(df_final_x_2, df_final_y_2, test_size=0.05, random_state=2000)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [metrics.AUC()])\n",
        "\n",
        "from imblearn.keras import balanced_batch_generator\n",
        "from imblearn.under_sampling import NearMiss\n",
        "training_generator, steps_per_epoch = balanced_batch_generator(X_train_d2, y_train_d2, sampler=NearMiss(), batch_size=10, random_state=42)\n",
        "callback_history = model.fit_generator(generator=training_generator,steps_per_epoch=steps_per_epoch,epochs=100, verbose=0)\n",
        "\n",
        "# # fit the keras model on the dataset\n",
        "# model.fit(X_train_d2, y_train_d2, epochs=100, batch_size=20)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_test_d2, y_test_d2)\n",
        "print('accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r25/25 [==============================] - 0s 2ms/step\n",
            "accuracy: 50.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opxa5GPL2_Ns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "ce1c3002-cd82-4a15-9768-8639003346e1"
      },
      "source": [
        "df_final_y_4 = df_final_1[\"R_4\"]\n",
        "df_final_x_4 = df_final_1.drop([\"R_1\",\"R_2\",\"R_6\",\"R_20\",\"R_4\",\"R_10\"], axis=1)\n",
        "X_train_d4, X_test_d4, y_train_d4, y_test_d4 = train_test_split(df_final_x_4, df_final_y_4, test_size=0.05, random_state=2000)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics = [metrics.AUC()])\n",
        "\n",
        "from imblearn.keras import balanced_batch_generator\n",
        "from imblearn.under_sampling import NearMiss\n",
        "training_generator, steps_per_epoch = balanced_batch_generator(X_train_d4, y_train_d4, sampler=NearMiss(), batch_size=10, random_state=42)\n",
        "callback_history = model.fit_generator(generator=training_generator,steps_per_epoch=steps_per_epoch,epochs=100, verbose=0)\n",
        "\n",
        "# # fit the keras model on the dataset\n",
        "# model.fit(X_train_d4, y_train_d4, epochs=200, batch_size=20)\n",
        "# # evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_test_d4, y_test_d4)\n",
        "print('accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r25/25 [==============================] - 0s 2ms/step\n",
            "accuracy: 31.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER9mGcys1ls7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "25680d5a-768b-46ee-ed73-8223fd05a461"
      },
      "source": [
        "df_final_y_6 = df_final_1[\"R_6\"]\n",
        "df_final_x_6 = df_final_1.drop([\"R_1\",\"R_2\",\"R_6\",\"R_20\",\"R_4\",\"R_10\"], axis=1)\n",
        "X_train_d6, X_test_d6, y_train_d6, y_test_d6 = train_test_split(df_final_x_6, df_final_y_6, test_size=0.05, random_state=2000)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics = [metrics.AUC()])\n",
        "\n",
        "from imblearn.keras import balanced_batch_generator\n",
        "from imblearn.under_sampling import NearMiss\n",
        "training_generator, steps_per_epoch = balanced_batch_generator(X_train_d4, y_train_d4, sampler=NearMiss(), batch_size=10, random_state=42)\n",
        "callback_history = model.fit_generator(generator=training_generator,steps_per_epoch=steps_per_epoch,epochs=100, verbose=0)\n",
        "# fit the keras model on the dataset\n",
        "# model.fit(X_train_d6, y_train_d6, epochs=200, batch_size=20)\n",
        "# # evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_test_d6, y_test_d6)\n",
        "print('accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r25/25 [==============================] - 0s 2ms/step\n",
            "accuracy: 8.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTOT47LG3PKE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a47da06f-aa29-4381-9759-b338130b4bd9"
      },
      "source": [
        "df_final_y_10 = df_final_1[\"R_10\"]\n",
        "df_final_x_10 = df_final_1.drop([\"R_1\",\"R_2\",\"R_6\",\"R_20\",\"R_4\",\"R_10\"], axis=1)\n",
        "X_train_d10, X_test_d10, y_train_d10, y_test_d10 = train_test_split(df_final_x_10, df_final_y_10, test_size=0.05, random_state=2000)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train_d10, y_train_d10, epochs=200, batch_size=20)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_test_d10, y_test_d10)\n",
        "print('accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "464/464 [==============================] - 0s 392us/step - loss: 13.8917 - accuracy: 0.8685\n",
            "Epoch 2/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 1.9835 - accuracy: 0.7629\n",
            "Epoch 3/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 1.1567 - accuracy: 0.8017\n",
            "Epoch 4/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 1.1075 - accuracy: 0.8017\n",
            "Epoch 5/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 1.1248 - accuracy: 0.7823\n",
            "Epoch 6/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 1.0323 - accuracy: 0.7694\n",
            "Epoch 7/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.6862 - accuracy: 0.7866\n",
            "Epoch 8/200\n",
            "464/464 [==============================] - 0s 71us/step - loss: 0.6021 - accuracy: 0.8082\n",
            "Epoch 9/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.6505 - accuracy: 0.8384\n",
            "Epoch 10/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.5882 - accuracy: 0.7953\n",
            "Epoch 11/200\n",
            "464/464 [==============================] - 0s 93us/step - loss: 0.4770 - accuracy: 0.8491\n",
            "Epoch 12/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.4954 - accuracy: 0.8578\n",
            "Epoch 13/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.4603 - accuracy: 0.8427\n",
            "Epoch 14/200\n",
            "464/464 [==============================] - 0s 86us/step - loss: 0.5306 - accuracy: 0.8534\n",
            "Epoch 15/200\n",
            "464/464 [==============================] - 0s 85us/step - loss: 0.5303 - accuracy: 0.8168\n",
            "Epoch 16/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.5393 - accuracy: 0.8448\n",
            "Epoch 17/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.5983 - accuracy: 0.8082\n",
            "Epoch 18/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.6229 - accuracy: 0.8427\n",
            "Epoch 19/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.5816 - accuracy: 0.8017\n",
            "Epoch 20/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.6175 - accuracy: 0.8384\n",
            "Epoch 21/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.6027 - accuracy: 0.7953\n",
            "Epoch 22/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4713 - accuracy: 0.8254\n",
            "Epoch 23/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4190 - accuracy: 0.8534\n",
            "Epoch 24/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.4827 - accuracy: 0.8599\n",
            "Epoch 25/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.4418 - accuracy: 0.8362\n",
            "Epoch 26/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4572 - accuracy: 0.8556\n",
            "Epoch 27/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.4301 - accuracy: 0.8599\n",
            "Epoch 28/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.4791 - accuracy: 0.8491\n",
            "Epoch 29/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.4190 - accuracy: 0.8491\n",
            "Epoch 30/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.5082 - accuracy: 0.8384\n",
            "Epoch 31/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.4611 - accuracy: 0.8491\n",
            "Epoch 32/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.5319 - accuracy: 0.8384\n",
            "Epoch 33/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.5529 - accuracy: 0.8254\n",
            "Epoch 34/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.4287 - accuracy: 0.8621\n",
            "Epoch 35/200\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.5013 - accuracy: 0.8599\n",
            "Epoch 36/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.4964 - accuracy: 0.8362\n",
            "Epoch 37/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4973 - accuracy: 0.8513\n",
            "Epoch 38/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.5144 - accuracy: 0.8491\n",
            "Epoch 39/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4507 - accuracy: 0.8534\n",
            "Epoch 40/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4004 - accuracy: 0.8621\n",
            "Epoch 41/200\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.3987 - accuracy: 0.8599\n",
            "Epoch 42/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3961 - accuracy: 0.8664\n",
            "Epoch 43/200\n",
            "464/464 [==============================] - 0s 92us/step - loss: 0.4010 - accuracy: 0.8664\n",
            "Epoch 44/200\n",
            "464/464 [==============================] - 0s 87us/step - loss: 0.4407 - accuracy: 0.8621\n",
            "Epoch 45/200\n",
            "464/464 [==============================] - 0s 94us/step - loss: 0.4088 - accuracy: 0.8556\n",
            "Epoch 46/200\n",
            "464/464 [==============================] - 0s 86us/step - loss: 0.4024 - accuracy: 0.8491\n",
            "Epoch 47/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3845 - accuracy: 0.8685\n",
            "Epoch 48/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4024 - accuracy: 0.8685\n",
            "Epoch 49/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.4190 - accuracy: 0.8534\n",
            "Epoch 50/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3891 - accuracy: 0.8621\n",
            "Epoch 51/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3713 - accuracy: 0.8621\n",
            "Epoch 52/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4004 - accuracy: 0.8664\n",
            "Epoch 53/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3722 - accuracy: 0.8750\n",
            "Epoch 54/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3786 - accuracy: 0.8642\n",
            "Epoch 55/200\n",
            "464/464 [==============================] - 0s 84us/step - loss: 0.4625 - accuracy: 0.8254\n",
            "Epoch 56/200\n",
            "464/464 [==============================] - 0s 86us/step - loss: 0.4219 - accuracy: 0.8599\n",
            "Epoch 57/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.4413 - accuracy: 0.8664\n",
            "Epoch 58/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3934 - accuracy: 0.8664\n",
            "Epoch 59/200\n",
            "464/464 [==============================] - 0s 71us/step - loss: 0.4191 - accuracy: 0.8470\n",
            "Epoch 60/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4008 - accuracy: 0.8685\n",
            "Epoch 61/200\n",
            "464/464 [==============================] - 0s 71us/step - loss: 0.4321 - accuracy: 0.8513\n",
            "Epoch 62/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4063 - accuracy: 0.8513\n",
            "Epoch 63/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4273 - accuracy: 0.8513\n",
            "Epoch 64/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.4778 - accuracy: 0.8254\n",
            "Epoch 65/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.6020 - accuracy: 0.8405\n",
            "Epoch 66/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4650 - accuracy: 0.8427\n",
            "Epoch 67/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.4152 - accuracy: 0.8578\n",
            "Epoch 68/200\n",
            "464/464 [==============================] - 0s 88us/step - loss: 0.3895 - accuracy: 0.8664\n",
            "Epoch 69/200\n",
            "464/464 [==============================] - 0s 82us/step - loss: 0.4062 - accuracy: 0.8599\n",
            "Epoch 70/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3942 - accuracy: 0.8728\n",
            "Epoch 71/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4508 - accuracy: 0.8470\n",
            "Epoch 72/200\n",
            "464/464 [==============================] - 0s 71us/step - loss: 0.3833 - accuracy: 0.8728\n",
            "Epoch 73/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3719 - accuracy: 0.8707\n",
            "Epoch 74/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.3767 - accuracy: 0.8621\n",
            "Epoch 75/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.4036 - accuracy: 0.8642\n",
            "Epoch 76/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.3782 - accuracy: 0.8664\n",
            "Epoch 77/200\n",
            "464/464 [==============================] - 0s 71us/step - loss: 0.3680 - accuracy: 0.8642\n",
            "Epoch 78/200\n",
            "464/464 [==============================] - 0s 82us/step - loss: 0.3847 - accuracy: 0.8707\n",
            "Epoch 79/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3750 - accuracy: 0.8728\n",
            "Epoch 80/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.4459 - accuracy: 0.8384\n",
            "Epoch 81/200\n",
            "464/464 [==============================] - 0s 71us/step - loss: 0.3718 - accuracy: 0.8685\n",
            "Epoch 82/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3710 - accuracy: 0.8685\n",
            "Epoch 83/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3660 - accuracy: 0.8707\n",
            "Epoch 84/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3937 - accuracy: 0.8707\n",
            "Epoch 85/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3558 - accuracy: 0.8664\n",
            "Epoch 86/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3761 - accuracy: 0.8707\n",
            "Epoch 87/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3851 - accuracy: 0.8642\n",
            "Epoch 88/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3815 - accuracy: 0.8642\n",
            "Epoch 89/200\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.3832 - accuracy: 0.8685\n",
            "Epoch 90/200\n",
            "464/464 [==============================] - 0s 86us/step - loss: 0.3845 - accuracy: 0.8707\n",
            "Epoch 91/200\n",
            "464/464 [==============================] - 0s 86us/step - loss: 0.3708 - accuracy: 0.8621\n",
            "Epoch 92/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3681 - accuracy: 0.8599\n",
            "Epoch 93/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3832 - accuracy: 0.8685\n",
            "Epoch 94/200\n",
            "464/464 [==============================] - 0s 88us/step - loss: 0.3707 - accuracy: 0.8707\n",
            "Epoch 95/200\n",
            "464/464 [==============================] - 0s 92us/step - loss: 0.3640 - accuracy: 0.8664\n",
            "Epoch 96/200\n",
            "464/464 [==============================] - 0s 94us/step - loss: 0.3569 - accuracy: 0.8750\n",
            "Epoch 97/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.3878 - accuracy: 0.8707\n",
            "Epoch 98/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3826 - accuracy: 0.8728\n",
            "Epoch 99/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3777 - accuracy: 0.8707\n",
            "Epoch 100/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.3577 - accuracy: 0.8707\n",
            "Epoch 101/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3912 - accuracy: 0.8513\n",
            "Epoch 102/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3596 - accuracy: 0.8728\n",
            "Epoch 103/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3577 - accuracy: 0.8707\n",
            "Epoch 104/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.3697 - accuracy: 0.8621\n",
            "Epoch 105/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3881 - accuracy: 0.8578\n",
            "Epoch 106/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3655 - accuracy: 0.8664\n",
            "Epoch 107/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3840 - accuracy: 0.8642\n",
            "Epoch 108/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3747 - accuracy: 0.8728\n",
            "Epoch 109/200\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.3714 - accuracy: 0.8556\n",
            "Epoch 110/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3543 - accuracy: 0.8664\n",
            "Epoch 111/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3505 - accuracy: 0.8750\n",
            "Epoch 112/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3513 - accuracy: 0.8728\n",
            "Epoch 113/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3451 - accuracy: 0.8728\n",
            "Epoch 114/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3543 - accuracy: 0.8707\n",
            "Epoch 115/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3515 - accuracy: 0.8772\n",
            "Epoch 116/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3915 - accuracy: 0.8707\n",
            "Epoch 117/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3765 - accuracy: 0.8664\n",
            "Epoch 118/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3495 - accuracy: 0.8728\n",
            "Epoch 119/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3485 - accuracy: 0.8685\n",
            "Epoch 120/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3450 - accuracy: 0.8728\n",
            "Epoch 121/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3478 - accuracy: 0.8750\n",
            "Epoch 122/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3494 - accuracy: 0.8728\n",
            "Epoch 123/200\n",
            "464/464 [==============================] - 0s 92us/step - loss: 0.3418 - accuracy: 0.8728\n",
            "Epoch 124/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.4015 - accuracy: 0.8556\n",
            "Epoch 125/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3408 - accuracy: 0.8664\n",
            "Epoch 126/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3567 - accuracy: 0.8728\n",
            "Epoch 127/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3510 - accuracy: 0.8728\n",
            "Epoch 128/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3618 - accuracy: 0.8642\n",
            "Epoch 129/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3894 - accuracy: 0.8578\n",
            "Epoch 130/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3853 - accuracy: 0.8728\n",
            "Epoch 131/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3586 - accuracy: 0.8642\n",
            "Epoch 132/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3676 - accuracy: 0.8707\n",
            "Epoch 133/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3403 - accuracy: 0.8728\n",
            "Epoch 134/200\n",
            "464/464 [==============================] - 0s 85us/step - loss: 0.3637 - accuracy: 0.8707\n",
            "Epoch 135/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3623 - accuracy: 0.8664\n",
            "Epoch 136/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3476 - accuracy: 0.8685\n",
            "Epoch 137/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3467 - accuracy: 0.8728\n",
            "Epoch 138/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3455 - accuracy: 0.8728\n",
            "Epoch 139/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3510 - accuracy: 0.8772\n",
            "Epoch 140/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3407 - accuracy: 0.8793\n",
            "Epoch 141/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3416 - accuracy: 0.8642\n",
            "Epoch 142/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.3802 - accuracy: 0.8642\n",
            "Epoch 143/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3478 - accuracy: 0.8728\n",
            "Epoch 144/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3413 - accuracy: 0.8664\n",
            "Epoch 145/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3493 - accuracy: 0.8728\n",
            "Epoch 146/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3542 - accuracy: 0.8707\n",
            "Epoch 147/200\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.3408 - accuracy: 0.8772\n",
            "Epoch 148/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3582 - accuracy: 0.8728\n",
            "Epoch 149/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3490 - accuracy: 0.8728\n",
            "Epoch 150/200\n",
            "464/464 [==============================] - 0s 89us/step - loss: 0.3468 - accuracy: 0.8685\n",
            "Epoch 151/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3394 - accuracy: 0.8728\n",
            "Epoch 152/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3400 - accuracy: 0.8664\n",
            "Epoch 153/200\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.3542 - accuracy: 0.8578\n",
            "Epoch 154/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3594 - accuracy: 0.8707\n",
            "Epoch 155/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3867 - accuracy: 0.8621\n",
            "Epoch 156/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3550 - accuracy: 0.8793\n",
            "Epoch 157/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.3322 - accuracy: 0.8750\n",
            "Epoch 158/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3640 - accuracy: 0.8642\n",
            "Epoch 159/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.3361 - accuracy: 0.8750\n",
            "Epoch 160/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3385 - accuracy: 0.8728\n",
            "Epoch 161/200\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.4002 - accuracy: 0.8470\n",
            "Epoch 162/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3368 - accuracy: 0.8750\n",
            "Epoch 163/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3581 - accuracy: 0.8750\n",
            "Epoch 164/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3495 - accuracy: 0.8728\n",
            "Epoch 165/200\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.3425 - accuracy: 0.8772\n",
            "Epoch 166/200\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.3447 - accuracy: 0.8707\n",
            "Epoch 167/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3469 - accuracy: 0.8750\n",
            "Epoch 168/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3592 - accuracy: 0.8664\n",
            "Epoch 169/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3637 - accuracy: 0.8707\n",
            "Epoch 170/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3366 - accuracy: 0.8728\n",
            "Epoch 171/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3501 - accuracy: 0.8772\n",
            "Epoch 172/200\n",
            "464/464 [==============================] - 0s 82us/step - loss: 0.3370 - accuracy: 0.8772\n",
            "Epoch 173/200\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.3539 - accuracy: 0.8685\n",
            "Epoch 174/200\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.3536 - accuracy: 0.8772\n",
            "Epoch 175/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3314 - accuracy: 0.8772\n",
            "Epoch 176/200\n",
            "464/464 [==============================] - 0s 86us/step - loss: 0.3393 - accuracy: 0.8750\n",
            "Epoch 177/200\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.3294 - accuracy: 0.8772\n",
            "Epoch 178/200\n",
            "464/464 [==============================] - 0s 88us/step - loss: 0.3433 - accuracy: 0.8685\n",
            "Epoch 179/200\n",
            "464/464 [==============================] - 0s 97us/step - loss: 0.3426 - accuracy: 0.8685\n",
            "Epoch 180/200\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.3353 - accuracy: 0.8728\n",
            "Epoch 181/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3282 - accuracy: 0.8728\n",
            "Epoch 182/200\n",
            "464/464 [==============================] - 0s 93us/step - loss: 0.3359 - accuracy: 0.8685\n",
            "Epoch 183/200\n",
            "464/464 [==============================] - 0s 96us/step - loss: 0.3359 - accuracy: 0.8707\n",
            "Epoch 184/200\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.3376 - accuracy: 0.8728\n",
            "Epoch 185/200\n",
            "464/464 [==============================] - 0s 82us/step - loss: 0.3531 - accuracy: 0.8470\n",
            "Epoch 186/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3460 - accuracy: 0.8707\n",
            "Epoch 187/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3725 - accuracy: 0.8534\n",
            "Epoch 188/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3456 - accuracy: 0.8728\n",
            "Epoch 189/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3439 - accuracy: 0.8728\n",
            "Epoch 190/200\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.3495 - accuracy: 0.8728\n",
            "Epoch 191/200\n",
            "464/464 [==============================] - 0s 80us/step - loss: 0.3694 - accuracy: 0.8621\n",
            "Epoch 192/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3679 - accuracy: 0.8685\n",
            "Epoch 193/200\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.3951 - accuracy: 0.8556\n",
            "Epoch 194/200\n",
            "464/464 [==============================] - 0s 78us/step - loss: 0.3422 - accuracy: 0.8685\n",
            "Epoch 195/200\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.3367 - accuracy: 0.8750\n",
            "Epoch 196/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3431 - accuracy: 0.8772\n",
            "Epoch 197/200\n",
            "464/464 [==============================] - 0s 87us/step - loss: 0.3370 - accuracy: 0.8772\n",
            "Epoch 198/200\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.3426 - accuracy: 0.8728\n",
            "Epoch 199/200\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.3362 - accuracy: 0.8728\n",
            "Epoch 200/200\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.3363 - accuracy: 0.8750\n",
            "25/25 [==============================] - 0s 749us/step\n",
            "accuracy: 80.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9kMiPiR1_Q4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "081e193a-2ea4-469c-f307-8fbd2c6691b4"
      },
      "source": [
        "df_final_y_20 = df_final_1[\"R_20\"]\n",
        "df_final_x_20 = df_final_1.drop([\"R_1\",\"R_2\",\"R_6\",\"R_20\",\"R_4\",\"R_10\"], axis=1)\n",
        "X_train_d20, X_test_d20, y_train_d20, y_test_d20 = train_test_split(df_final_x_20, df_final_y_20, test_size=0.05, random_state=2000)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25, input_dim=20, activation='relu'))\n",
        "model.add(Dense(18, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train_d20, y_train_d20, epochs=50, batch_size=20)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_test_d20, y_test_d20)\n",
        "print('accuracy: %.2f' % (accuracy*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "464/464 [==============================] - 0s 407us/step - loss: 70.2749 - accuracy: 0.8362\n",
            "Epoch 2/50\n",
            "464/464 [==============================] - 0s 76us/step - loss: 7.1968 - accuracy: 0.5323\n",
            "Epoch 3/50\n",
            "464/464 [==============================] - 0s 72us/step - loss: 1.7429 - accuracy: 0.4224\n",
            "Epoch 4/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.7646 - accuracy: 0.6724\n",
            "Epoch 5/50\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.7260 - accuracy: 0.8362\n",
            "Epoch 6/50\n",
            "464/464 [==============================] - 0s 70us/step - loss: 0.6892 - accuracy: 0.8362\n",
            "Epoch 7/50\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.6585 - accuracy: 0.8362\n",
            "Epoch 8/50\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.6358 - accuracy: 0.8362\n",
            "Epoch 9/50\n",
            "464/464 [==============================] - 0s 71us/step - loss: 0.6192 - accuracy: 0.8362\n",
            "Epoch 10/50\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.5812 - accuracy: 0.8362\n",
            "Epoch 11/50\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.5939 - accuracy: 0.8362\n",
            "Epoch 12/50\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.5873 - accuracy: 0.8362\n",
            "Epoch 13/50\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.5811 - accuracy: 0.8362\n",
            "Epoch 14/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.5759 - accuracy: 0.8362\n",
            "Epoch 15/50\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.5707 - accuracy: 0.8362\n",
            "Epoch 16/50\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.5604 - accuracy: 0.8362\n",
            "Epoch 17/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.5766 - accuracy: 0.8362\n",
            "Epoch 18/50\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.5603 - accuracy: 0.8362\n",
            "Epoch 19/50\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.5516 - accuracy: 0.8362\n",
            "Epoch 20/50\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.5467 - accuracy: 0.8362\n",
            "Epoch 21/50\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.5405 - accuracy: 0.8362\n",
            "Epoch 22/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.5365 - accuracy: 0.8362\n",
            "Epoch 23/50\n",
            "464/464 [==============================] - 0s 69us/step - loss: 0.5349 - accuracy: 0.8362\n",
            "Epoch 24/50\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.5307 - accuracy: 0.8362\n",
            "Epoch 25/50\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.5254 - accuracy: 0.8362\n",
            "Epoch 26/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.5198 - accuracy: 0.8362\n",
            "Epoch 27/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.5145 - accuracy: 0.8362\n",
            "Epoch 28/50\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.5108 - accuracy: 0.8362\n",
            "Epoch 29/50\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.5091 - accuracy: 0.8362\n",
            "Epoch 30/50\n",
            "464/464 [==============================] - 0s 85us/step - loss: 0.5042 - accuracy: 0.8362\n",
            "Epoch 31/50\n",
            "464/464 [==============================] - 0s 82us/step - loss: 0.5013 - accuracy: 0.8362\n",
            "Epoch 32/50\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.5051 - accuracy: 0.8362\n",
            "Epoch 33/50\n",
            "464/464 [==============================] - 0s 82us/step - loss: 0.4988 - accuracy: 0.8362\n",
            "Epoch 34/50\n",
            "464/464 [==============================] - 0s 73us/step - loss: 0.4966 - accuracy: 0.8362\n",
            "Epoch 35/50\n",
            "464/464 [==============================] - 0s 79us/step - loss: 0.4933 - accuracy: 0.8362\n",
            "Epoch 36/50\n",
            "464/464 [==============================] - 0s 81us/step - loss: 0.4921 - accuracy: 0.8362\n",
            "Epoch 37/50\n",
            "464/464 [==============================] - 0s 72us/step - loss: 0.4909 - accuracy: 0.8362\n",
            "Epoch 38/50\n",
            "464/464 [==============================] - 0s 70us/step - loss: 0.4886 - accuracy: 0.8362\n",
            "Epoch 39/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4853 - accuracy: 0.8362\n",
            "Epoch 40/50\n",
            "464/464 [==============================] - 0s 82us/step - loss: 0.4821 - accuracy: 0.8362\n",
            "Epoch 41/50\n",
            "464/464 [==============================] - 0s 87us/step - loss: 0.4801 - accuracy: 0.8362\n",
            "Epoch 42/50\n",
            "464/464 [==============================] - 0s 77us/step - loss: 0.4781 - accuracy: 0.8362\n",
            "Epoch 43/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4762 - accuracy: 0.8362\n",
            "Epoch 44/50\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4743 - accuracy: 0.8362\n",
            "Epoch 45/50\n",
            "464/464 [==============================] - 0s 76us/step - loss: 0.4727 - accuracy: 0.8362\n",
            "Epoch 46/50\n",
            "464/464 [==============================] - 0s 69us/step - loss: 0.4711 - accuracy: 0.8362\n",
            "Epoch 47/50\n",
            "464/464 [==============================] - 0s 74us/step - loss: 0.4694 - accuracy: 0.8362\n",
            "Epoch 48/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4679 - accuracy: 0.8362\n",
            "Epoch 49/50\n",
            "464/464 [==============================] - 0s 75us/step - loss: 0.4685 - accuracy: 0.8362\n",
            "Epoch 50/50\n",
            "464/464 [==============================] - 0s 83us/step - loss: 0.4668 - accuracy: 0.8362\n",
            "25/25 [==============================] - 0s 785us/step\n",
            "accuracy: 96.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsoN7Q9M2iQJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}